---
title: "Final Project"
author: "Timothy Lanthier"
date: "3/12/2022"
output: pdf_document
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(knitr)
library(patchwork)
library(broom)
library(leaps)
library(Hmisc)
library(corrplot)
library(RColorBrewer)
library(rms)
```

## Introduction

```{r echo = FALSE}
youtube_raw <- read.csv('data/youtube_data.csv') %>%
  subset(select = -c(X)) %>%
  mutate(trending_date = as.Date(trending_date),  # strip time since all trending dates recorded at time 0
         publishedAt = as.POSIXct(publishedAt),
         weekday_published = as.factor(weekday_published))

youtube_raw$desc_length[is.na(youtube_raw$desc_length)] <- 0
youtube_raw <- youtube_raw %>%
  drop_na()

levels(youtube_raw$weekday_published) = c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday','Sunday')


youtube <- youtube_raw %>%
  subset(select = -c(video_id, channelId, categoryId, tags, description, title, trending_date, likes, dislikes, comment_count, trending_age, channelTitle))
```

  For content creators on Youtube, their income is largely determined by the popularity of their videos. The most obvious source of income for creators is revenue from ads. The more views your video gets, the more ads are served and the more a creator might get paid. Additionally, higher view counts on videos may result in sponsorship deals for creators which serve an additional source of income. Hence, it is important for creators on Youtube to maximize the number of views that they get on videos. Of course the success of a Youtube video depends on the content in the video itself, but how much is the view count of a video associated with other aspects such as the title or time of upload?
  
In this paper, we will explore how certain characteristics of trending Youtube videos are associated with view count. We wish to find what aspects of a video such as length of the title or time of upload may be associated with the view count a Youtube video.

The dataset was obtained through [Kaggle](https://www.kaggle.com/rsrishav/youtube-trending-video-dataset?select=US_youtube_trending_data.csv) and includes as observations all trending videos from August of 2020 to now from a variety of regions. For this analysis, we will only be using trending videos from the US. Note that the dataset we will be using was accessed from Kaggle on February 7, 2022, so we will only include trending Youtube videos up to that date. From this dataset, we have taken a random sample of 1000 videos and have generated some additional variables from the dataset. We also used the Youtube API with the provided video and channel IDs to gain additional potential predictors such as video length and subscriber counts for the channels. Our feature generation procedure left us with a few different missing values. There were some missing subscriber counts as well as video lengths due to videos and channels no longer existing. Since there were very few of those observations, we have removed them from our dataset. Additionaly, some videos had no description leading to missing values. So for those videos we imputed the description length of be 0 characters. 

We also removed variables such as `likes`, `dislikes`, and `trending_age` since those values would not be observed until after the video is uploaded. Since we want to look at variables which can only be observed before the video is uploaded, those will not be important for our analysis. This leaves us with a dataset with 973 observations and the following 20 variables:

|Variable|Description|
|---|---|
|publishedAt | date and time of upload (PST)|
|view_count| number of views|
|comments_disabled| comments are disabled (T/F)|
|ratings_disabled| ratings are disabled (T/F)|
|num_tags| number of tags in video|
|num_caps| number of capital letters in title|
|num_exc| number of exclamation points in title|
|num_qm| number of question marks in title|
|num_period| number of periods in title|
|num_dollar| number of dollar signs in title|
|title_length| length of title in characters|
|desc_length| length of description in characters|
|channel_length| length of channel name in characters|
|weekday_published| weekday of video upload|
|day_published| day of month video was uploaded|
|hour_published| hour of day video was published|
|video_length| length of video in seconds|
|subscriberCount| number of subscribers on publisher's channel|
|videoCount| number of videos on publisher's channel|
|category| video category|
   
Looking at the response variable of view count, we find that the distribution for view count has a heavy positive skew. Since we wish to conduct inference on our model, we will instead be using the logarithm of view count so as to have a more normally distributed response variable. The distributions for both variables are shown below.

```{r echo = FALSE}
youtube <- youtube %>% 
  mutate(log_views = log(view_count))

p1<- ggplot(data = youtube, aes(view_count)) +
  geom_histogram(bins = 50)+
  labs(x = 'View Count', title = 'Distribution of View Count')

p2<- ggplot(data = youtube, aes(log_views)) +
  geom_histogram(bins = 50)+
  labs(x = 'Log View Count', title = 'Distribution of Log View Count')

p1+p2
```

Interestingly, looking at the plots for log view count against the number of tags, we see what appears to be a completely random scatter. So there appears to be no relationship between log view count and the number of tags a video has. This is quite surprising as I would expect a large number of tags might result in the video getting suggested to more users and thus more people viewing the video.
```{r echo = FALSE}
ggplot(data = youtube, aes(x = num_tags, y = log_views)) +
  geom_point() +
  labs(x = 'Number of Tags', y = 'Log Views', title = 'Number of Tags vs Log View Count')
```

Meanwhile looking at the box plots for log view count across the categories of videos, we find that there are some large differences in log view count across the different video categories. While the variability varies between the categories, just looking at the means, we have comedy and SciFi/Fantasy videos appears to be the most popular while foreign, horror, and music videos appear to have the lowest mean log view counts. So video category may be useful in our model. What seemed unusual is that videos in the Music category have such a low mean log view count. Just based off my own observations of trending videos, it seems that music videos which hit trending tend to have pretty high view counts.

```{r echo=FALSE}
ggplot(data = youtube, aes(x = category, y = log_views)) +
  geom_boxplot()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))+
  labs(x = 'Video Category', y = 'Log Views', title = 'Video Category vs Log View Count')
```

While we will not include all of the plots from our exploratory data analysis, we identified quite a few variables that we thought may be useful for our final model. In addition to those mentioned above, these included the variables `subscriberCount`, `comments_disabled`, `ratings_disabled`, `num_caps`, `num_exc`, `num_period`, `num_dollar`, `desc_length`, `hour_published`, `weekday_published`, `video_length`.

```{r echo = FALSE}
library(corrplot)
library(RColorBrewer)
youtube_num <- youtube %>%
  subset(select = -c(publishedAt, view_count, comments_disabled, ratings_disabled, weekday_published, category))
M <-cor(youtube_num)
corrplot(M, type="upper", method="color")
```
Looking at the correlation plots, we can see that `subscriberCount` has a moderate correlation with log views. We also find that `num_caps` and `num_exc` have a weak correlation with log views. Additionally we see that the hour published has a very weak correlation. But from our exploratory data analysis, we found that there was quite a bit of variability of log view count for the different hours published so we will investigate its use further.


## Regression Analysis

As mentioned earlier, rather than using view count as our response variable, we have decided to use log view count since we intend on conducting inference on our model. For constructing our final model, we started by creating a model using all of the variables we identified as potentially important:

`subscriberCount`, `category`, `comments_disabled`, `ratings_disabled`, `num_caps`, `num_exc`, `num_period`, `num_dollar`, `desc_length`, `hour_published`, `weekday_published`, `video_length`

```{r echo = FALSE, results = 'hide'}
full_model_factor <- lm(log_views ~ subscriberCount + category + comments_disabled + ratings_disabled + num_caps + as.factor(num_exc) + as.factor(num_period) + as.factor(num_dollar) + desc_length + hour_published + weekday_published + day_published + video_length, data = youtube)

full_model_int <- lm(log_views ~ subscriberCount + category + comments_disabled + ratings_disabled + num_caps + num_exc + num_period + num_dollar + desc_length + hour_published + weekday_published + day_published + video_length, data = youtube)

tidy(full_model_factor)
tidy(full_model_int)

glance(full_model_factor)
glance(full_model_int)

tidy(full_model_int, conf.int=TRUE) %>%
  kable(digits = 3)
```

We built 2 models using these variables. One model had `num_exc`, `num_period`, and `num_dollar` treated as categorical since there were so few values and the other model treated them as integer values. Our categorical model had an $R^2$ of 0.285 and AIC of 2842.164. Our integer model had an $R^2$ of 0.273 and AIC of 2836.423. Since the $R^2$ values between the 2 models are quite close, we decided to choose the model with the above variables treated as integers due to having a lower AIC.

Next, we checked whether or not to treat `hour_published` as numeric. As we noticed the correlation table, the correlation between the hour published and log view count is extremely weak. But we found in our data analysis that the log view count across different hours varied quite a bit, just not in a linear fashion with respect to hour.

```{r echo =FALSE, results = 'hide'}
youtube <- youtube %>%
  mutate(time_of_day = cut(hour_published, right = FALSE, breaks = c(0,6,12,18,24), labels = c('12am_to_5am', '6am_to_11am', '12pm_to_5pm', '6pm_to_11pm')))
model_hour_int <- lm(log_views ~ hour_published + subscriberCount + category + comments_disabled + ratings_disabled + num_caps + num_exc + num_period + 
                       num_dollar + desc_length + weekday_published + day_published + video_length, data = youtube)
model_hour_cat_4 <- lm(log_views ~ time_of_day + subscriberCount + category + comments_disabled + ratings_disabled + num_caps + num_exc + num_period + 
                       num_dollar + desc_length + weekday_published + day_published + video_length, data = youtube)
model_hour_cat <- lm(log_views ~ as.factor(hour_published) + subscriberCount + category + comments_disabled + ratings_disabled + num_caps + num_exc+
                         num_period + num_dollar + desc_length + weekday_published + day_published + video_length, data = youtube)
tidy(model_hour_int, conf.int = TRUE) %>%
  kable(digits = 3)
tidy(model_hour_cat_4, conf.int = TRUE) %>%
  kable(digits = 3)
tidy(model_hour_cat, conf.int = TRUE) %>%
  kable(digits = 3)

glance(model_hour_int)
glance(model_hour_cat_4)
glance(model_hour_cat)


```

We tested 3 different models: one with `hour_published` treated as numeric, one with `hour_published` treated as categorical with 24 categories, and one with `hour_published` treated as categorical with 4 categories, each one being a 6 hour interval. We found that our numeric model and model with 4 categories to have similar values for $R^2$ of around 0.274 while our model with 24 categories for `hour_published`, we got an $R^2$ of 0.294. However, the AIC and BIC of our last model was significantly greater than that of our other 2 models. So we decided to choose the model with the best AIC being the model with 4 categories for hour published. We called this variable with 4 categories `time_of_day`.

```{r echo = FALSE, results = 'hide', message = FALSE}
model_back_selection <- step(model_hour_cat_4, direction = 'backward')
tidy(model_back_selection, conf.int = TRUE) %>%
  kable(format = 'markdown')
```

```{r echo =FALSE, results = 'hide'}
glance(lm(log_views ~ time_of_day + subscriberCount + category + num_caps + 
    num_exc + desc_length + video_length, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount + category + num_caps + 
    num_exc + desc_length + video_length + ratings_disabled, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount + category + num_caps + 
    num_exc + desc_length + video_length + day_published, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount + category + num_caps + 
    num_exc + desc_length + video_length + num_dollar, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount + category + num_caps + 
    num_exc + desc_length + video_length + comments_disabled, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount + category + num_caps + 
    num_exc + desc_length + video_length + num_period, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount + category + num_caps + 
    num_exc + desc_length + video_length + weekday_published, data = youtube))

model <- lm(log_views ~ time_of_day+ subscriberCount + category + num_caps + 
    num_exc + desc_length + video_length, data = youtube)
```


Next we ran backwards selection on this model using AIC. This gave us a model with `time_of_day`, `subscriberCount`, `category`, `num_caps`, `num_exc`, `desc_length`, and `video_length` as the best model. Just to make sure we didn't miss any important variables, we added back in some of the variables to check whether there would be an improvement, but none of the variables led to any significant increase in $R^2$. We noted that there may be some interactions between `category` and other variables, so we checked some potential interactions between `category` and found that interactions between `time_of_day` and `category`, `category` and `subscriberCount`, and `category` and `desc_length` to yield significant increases in $R^2$ for our model. We then checked all possible models with these different interaction terms and chose the model with the lowest AIC.

```{r echo = FALSE, results = 'hide'}
glance(model)

glance(lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + time_of_day*category, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*subscriberCount, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*num_caps, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*desc_length, data = youtube))
glance(lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*video_length, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*num_exc, data = youtube))

```

```{r eval = FALSE}
glance(lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*time_of_day + category*subscriberCount + category*desc_length, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*time_of_day + category*subscriberCount, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*time_of_day + category*desc_length, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*subscriberCount + category*desc_length, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*time_of_day, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*subscriberCount, data = youtube))

glance(lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*desc_length, data = youtube))
```

This gave us the final model which includes the predictor variables `time_of_day`, `subscriberCount`, `category`, `num_caps`, `num_exc`, `desc_length`, `video_length` and the interactions between `category` and both `desc_length` and `subscriberCount`. The coefficients for our final model are shown on the following page.


\newpage

```{r echo = FALSE}
final_model <- lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*subscriberCount + category*desc_length, data = youtube)

final_model_aug <- augment(final_model) %>%
  mutate(obs_num = 1:n())

tidy(final_model, conf.int = TRUE) %>%
  kable(digits = 4, format = 'markdown')

final_model_no_sub <- lm(log_views ~ time_of_day +category + num_caps + 
    num_exc + desc_length + video_length + category*desc_length, data = youtube)

final_model_no_cat <- lm(log_views ~ time_of_day + subscriberCount +category + num_caps + 
    num_exc + desc_length + video_length + category*subscriberCount + category*desc_length, data = youtube)

```

```{r eval=FALSE}
glance(final_model)
glance(final_model_no_sub)
```



|$R^2$| AIC | BIC|
|---|---|---|---|
|0.3396|2777.482|3016.621|

Even though `subscriberCount` has a very large p-value, we found excluding it and its interactions from the models resulted in a considerable drop in $R^2$ of over 0.2. We also investigated whether there were any influential points in our dataset. While we found there were quite a few observations which lied outside our threshold for leverage and standardized residuals, looking at the cook's distance, we found that removing these observations would have little effect on our model. The plots for leverage, standardized residuals, and cook's distance are shown below.

```{r echo = FALSE}
thresh = (2*(length(final_model$coefficients)+1))/973

l1 <- ggplot(data = final_model_aug, aes(x = obs_num, y = .hat))+
  geom_point() +
  geom_hline(yintercept = thresh, color = 'red') +
  labs(x = 'Observation Number', y = 'Leverage')

l2 <- ggplot(data = final_model_aug, aes(x = .fitted, y = .std.resid))+
  geom_point() +
  geom_hline(yintercept = -2, color = 'red')+
  geom_hline(yintercept = 2, color = 'red') +
  labs(x = 'Fitted Values', y='Standard Residuals')

l3 <- ggplot(data = final_model_aug, aes(x = obs_num, y = .cooksd))+
  geom_point() +
  geom_hline(yintercept = 1, color = 'red')+
  labs(x = 'Observation Number', y='Cooks Distance')

l1 + l2 + l3
```

Seeing as our model is a multiple linear regression model, we have quite a few assumptions which needed to be checked if we wish to conduct inference on the coefficients. The first assumption is that `log_views` is normally distributed. As we noted before, the distribution for `log_views` seems to be approximately normal. We also have the following distribution and QQ plot of the residuals.

```{r echo = FALSE}
n1 <- ggplot(data = final_model_aug, aes(x =.resid)) +
  geom_histogram(bins = 50)+
  labs(x = 'Residuals', title = 'Distribution of Residuals')

n2 <-ggplot(data = final_model_aug, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line(color = 'red') +
  labs(x = 'Theoretical Quantiles', y = 'Sample Quantiles', title = 'Normal QQ Plot')
  
n1+n2
```
As we see the residuals seem to be normally distributed, although we have a longer right tail. This is reflected in our QQ plot as the residuals don't appear to follow the normal distribution for the larger residuals. So the normality assumption is partially satisfied.

The next assumption we need to check is that the regression variance is constant. We can check this by looking at our predictions versus the residuals shown in the plot below. As we can see, for middling predicted log view count, we have a lot of variability in the residuals. Meanwhile for very large or small predicted log views, we have considerably less variability in the residuals. Hence the constant variance assumption has been violated.

```{r}
ggplot(data = final_model_aug, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, color = 'red') +
  labs(x = 'Fitted Values', y = 'Residuals', title = 'Predicted Log View Count vs Residuals')
```

We also must check that `log_views` has a linear relationship with the predictor variables used in our model. Looking at the above plot, there isn't a clear pattern in our plot so it looks like a linear relationship may be appropriate. We also found that looks at the plots of the residuals against each of the predictors, there was no discernable pattern. The only exception was for `num_exc` where the average residuals seemed to be higher for videos with more exclamation points in the title. That being said, it seems that the linearity assumption was satisfied.

```{r eval = FALSE}
l1 <- ggplot(data = final_model_aug, aes(x = time_of_day, y=.resid)) +
  geom_boxplot()+
  labs(x = 'Time of Day', y = 'Residuals')

l2 <- ggplot(data = final_model_aug, aes(x = category, y=.resid)) +
  geom_point()+
  labs(x = 'Category', y = 'Residuals')

l3 <- ggplot(data = final_model_aug, aes(x = subscriberCount, y=.resid)) +
  geom_point()+
  labs(x = 'Number of Subscribers', y = 'Residuals')+
  geom_smooth(method = 'lm')

l4 <- ggplot(data = final_model_aug, aes(x = num_caps, y=.resid)) +
  geom_point()+
  labs(x = 'Number of Capital Letters in Title', y = 'Residuals') +
  geom_smooth(method = 'lm')

l5 <- ggplot(data = final_model_aug, aes(x = as.factor(num_exc), y=.resid)) +
  geom_boxplot()+
  labs(x = 'Number of Exclamation Points in Title', y = 'Residuals')

l6 <- ggplot(data = final_model_aug, aes(x = desc_length, y=.resid)) +
  geom_point()+
  labs(x = 'Length of Description (characters)', y = 'Residuals')+
  geom_smooth(method = 'lm')

l7 <- ggplot(data = final_model_aug, aes(x = video_length, y=.resid)) +
  geom_point()+
  labs(x = 'Length of video (seconds)', y = 'Residuals') +
  geom_smooth(method = 'lm')

l1+l2
l3+l4
l5+l6
l7
```
The final assumption is the independence assumption. Plotting the residuals against the time the videos were trending (and subsequently added to the dataset), we find that the residuals are randomly scattered around 0. So the independence assumption has been satisfied. Additionally, 

```{r echo = FALSE}
pub_dates <- youtube_raw %>% 
  subset(select = trending_date) %>% 
  mutate(obs_num = 1:n())

final_model_aug_pub_dates <- inner_join(final_model_aug, pub_dates, by = 'obs_num')

ggplot(data = final_model_aug_pub_dates, aes(x = trending_date, y = .resid))+
  geom_point() +
  geom_hline(yintercept = 0, color = 'red') +
  labs(x = 'Trending Date', y = 'Residuals', title = 'Residuals vs Date Trending')
```

Since the constant variance assumption has been violated and the normality assumption is only partially satisfied, it would be inappropriate to conduct inference on the coefficients of our model. 


## Discussion

As mentioned in the previous section, since the assumptions of our model (linearity, constant variance, independence, and normality) have not all been satisfied, we should be cautious when interpreting the coefficients of our model.
 
## Limitations

## Conclusion

## Additional Work

